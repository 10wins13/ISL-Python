{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5674ff7c",
   "metadata": {},
   "source": [
    "<h3><b> Chapter 10: Deep Learning </b></h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b457f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Torch-specific imports\n",
    "import torch\n",
    "import json\n",
    "from torch import nn\n",
    "from torch.optim import RMSprop\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchmetrics import MeanAbsoluteError, R2Score\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning import seed_everything\n",
    "from ISLP.torch import SimpleDataModule, SimpleModule, ErrorTracker, rec_num_workers\n",
    "from ISLP.torch.imdb import load_lookup, load_tensor, load_sparse, load_sequential\n",
    "from glob import glob\n",
    "from torchinfo import summary\n",
    "from torchvision.io import read_image\n",
    "from torchvision.datasets import MNIST, CIFAR100\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.transforms import Resize, Normalize, CenterCrop, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2456e93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n"
     ]
    }
   ],
   "source": [
    "seed_everything(0, workers=True)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca2e593",
   "metadata": {},
   "source": [
    "<b> Q7 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92153c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "DefaultModel                             [8000, 3]                 [8000]                    --\n",
       "├─Flatten: 1-1                           [8000, 3]                 [8000, 3]                 --\n",
       "├─Sequential: 1-2                        [8000, 3]                 [8000, 1]                 --\n",
       "│    └─Linear: 2-1                       [8000, 3]                 [8000, 10]                40\n",
       "│    └─ReLU: 2-2                         [8000, 10]                [8000, 10]                --\n",
       "│    └─Dropout: 2-3                      [8000, 10]                [8000, 10]                --\n",
       "│    └─Linear: 2-4                       [8000, 10]                [8000, 1]                 11\n",
       "===================================================================================================================\n",
       "Total params: 51\n",
       "Trainable params: 51\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.41\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.10\n",
       "Forward/backward pass size (MB): 0.70\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.80\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "default = load_data('Default').dropna()\n",
    "n = default.shape[0]\n",
    "\n",
    "# Data preprocessing\n",
    "model = MS(default.columns.drop(\"default\"), intercept=False)\n",
    "X = model.fit_transform(default).to_numpy()\n",
    "Y = np.where(default[\"default\"] == \"Yes\", 1, 0)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=1/5, random_state=1)\n",
    "\n",
    "# Specifying neural network\n",
    "class DefaultModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super(DefaultModel, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(input_size, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(10, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return torch.flatten(self.sequential(x))\n",
    "default_model = DefaultModel(X.shape[1])\n",
    "summary(default_model, input_size=X_train.shape, col_names=[\"input_size\", \"output_size\", \"num_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9776e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "X_train_t = torch.tensor(X_train.astype(np.float32))\n",
    "Y_train_t = torch.tensor(Y_train.astype(np.float32))\n",
    "X_test_t = torch.tensor(X_test.astype(np.float32))\n",
    "Y_test_t = torch.tensor(Y_test.astype(np.float32))\n",
    "default_train = TensorDataset(X_train_t, Y_train_t)\n",
    "default_test = TensorDataset(X_test_t, Y_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3477f651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type         | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | model | DefaultModel | 51     | train\n",
      "1 | loss  | MSELoss      | 0      | train\n",
      "-----------------------------------------------\n",
      "51        Trainable params\n",
      "0         Non-trainable params\n",
      "51        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 250/250 [00:01<00:00, 187.24it/s, v_num=3]       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 250/250 [00:01<00:00, 186.31it/s, v_num=3]\n",
      "Testing DataLoader 0: 100%|██████████| 63/63 [00:00<00:00, 336.03it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_MAE            0.0662161111831665\n",
      "        test_loss          0.028720347210764885\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.028720347210764885, 'test_MAE': 0.0662161111831665}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max workers = 12 for this PC\n",
    "max_num_workers = rec_num_workers()\n",
    "default_dm = SimpleDataModule(default_train, \n",
    "                              default_test,\n",
    "                              batch_size=32,\n",
    "                              num_workers=min(4, max_num_workers),\n",
    "                              validation=default_test)\n",
    "default_module = SimpleModule.regression(default_model, metrics={\"MAE\":MeanAbsoluteError()})\n",
    "default_logger = CSVLogger(\"logs\", name=\"default\")\n",
    "\n",
    "# Trainer\n",
    "default_trainer = Trainer(deterministic=True,\n",
    "                          max_epochs=50,\n",
    "                          log_every_n_steps=5,\n",
    "                          logger=default_logger,\n",
    "                          callbacks=[ErrorTracker()])\n",
    "default_trainer.fit(default_module, datamodule=default_dm)\n",
    "default_trainer.test(default_module, datamodule=default_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2cded12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0662, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary of results\n",
    "default_results = pd.read_csv(default_logger.experiment.metrics_file_path)\n",
    "def summary_plot(results,\n",
    "                 ax,\n",
    "                 col='loss',\n",
    "                 valid_legend='Validation',\n",
    "                 training_legend='Training',\n",
    "                 ylabel='Loss',\n",
    "                 fontsize=20):\n",
    "    for (column, color, label) in zip([f'train_{col}_epoch',\n",
    "                                       f'valid_{col}'],\n",
    "                                      ['black', 'red'],\n",
    "                                      [training_legend, valid_legend]):\n",
    "        results.plot(x='epoch', y=column, label=label, marker='o', color=color, ax=ax)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    return ax\n",
    "\n",
    "fig, ax = subplots(1, 1, figsize=(6, 6))\n",
    "ax = summary_plot(default_results,\n",
    "                  ax,\n",
    "                  col='MAE',\n",
    "                  ylabel='MAE',\n",
    "                  valid_legend='Validation (=Test)')\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_xticks(np.linspace(0, 50, 11).astype(int));\n",
    "\n",
    "default_model.eval() \n",
    "preds = default_module(X_test_t)\n",
    "print(torch.abs(Y_test_t - preds).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c48b971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026\n"
     ]
    }
   ],
   "source": [
    "# Comparison with linear logit\n",
    "logit = LogisticRegression().fit(X_train, Y_train)\n",
    "ypred = logit.predict(X_test)\n",
    "mae = np.abs(Y_test - ypred).mean()\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a75358",
   "metadata": {},
   "source": [
    "Using MAE, linear logistic regression outperforms deep learning. This may be due to the training set size to be not as large for deep learning to have its use (n=8000 for k=51)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b0c4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del(default,\n",
    "    default_model, default_dm,\n",
    "    default_logger,\n",
    "    default_test, default_train,\n",
    "    X, Y,\n",
    "    X_test, X_train,\n",
    "    Y_test, Y_train,\n",
    "    X_test_t, Y_test_t,\n",
    "    default_trainer, default_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68efaaac",
   "metadata": {},
   "source": [
    "<b> Q9 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5fe5eaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value = 0.4129\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "NYSE = load_data('NYSE')\n",
    "cols = ['DJ_return', 'log_volume', 'log_volatility']\n",
    "X = pd.DataFrame(StandardScaler(with_mean=True, with_std=True).fit_transform(NYSE[cols]),\n",
    "                 columns=NYSE[cols].columns,\n",
    "                 index=NYSE.index)\n",
    "\n",
    "# Create lagged data\n",
    "for lag in range(1, 6):\n",
    "    for col in cols:\n",
    "        newcol = np.zeros(X.shape[0]) * np.nan\n",
    "        newcol[lag:] = X[col].values[:-lag]\n",
    "        X.insert(len(X.columns), \"{0}_{1}\".format(col, lag), newcol)\n",
    "X.insert(len(X.columns), 'train', NYSE['train'])\n",
    "X = X.dropna()\n",
    "\n",
    "# Split X and Y\n",
    "Y, train = X['log_volume'], X['train']\n",
    "X = X.drop(columns=['train'] + cols)\n",
    "\n",
    "# Fit AR5 Model\n",
    "M = LinearRegression()\n",
    "M.fit(X[train], Y[train])\n",
    "print(f\"R-squared value = {round(M.score(X[~train], Y[~train]), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fb829ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared value = 0.4117\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "NYSE = load_data('NYSE')\n",
    "cols = ['DJ_return', 'log_volume', 'log_volatility']\n",
    "X = pd.DataFrame(StandardScaler(with_mean=True, with_std=True).fit_transform(NYSE[cols]),\n",
    "                 columns=NYSE[cols].columns,\n",
    "                 index=NYSE.index)\n",
    "\n",
    "# Create lagged data\n",
    "for lag in range(1, 6):\n",
    "    for col in cols:\n",
    "        newcol = np.zeros(X.shape[0]) * np.nan\n",
    "        newcol[lag:] = X[col].values[:-lag]\n",
    "        X.insert(len(X.columns), \"{0}_{1}\".format(col, lag), newcol)\n",
    "X.insert(len(X.columns), 'train', NYSE['train'])\n",
    "\n",
    "# Add 12-level variable \"month\"\n",
    "X.index = pd.to_datetime(X.index)\n",
    "X[\"month\"] = X.index.month\n",
    "X = X.dropna()\n",
    "\n",
    "# Split X and Y\n",
    "Y, train = X['log_volume'], X['train']\n",
    "X = X.drop(columns=['train'] + cols)\n",
    "\n",
    "# Fit AR5 Model\n",
    "M = LinearRegression()\n",
    "M.fit(X[train], Y[train])\n",
    "print(f\"R-squared value = {round(M.score(X[~train], Y[~train]), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c9c3ba",
   "metadata": {},
   "source": [
    "The factor does not improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a43bdd",
   "metadata": {},
   "source": [
    "<b> Q10 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addefcba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3ea68f4",
   "metadata": {},
   "source": [
    "<b> Q12 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d419280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with variable day_of_week as dummy\n",
    "NYSE = load_data('NYSE')\n",
    "cols = ['DJ_return', 'log_volume', 'log_volatility']\n",
    "X = pd.DataFrame(StandardScaler(with_mean=True, with_std=True).fit_transform(NYSE[cols]),\n",
    "                 columns=NYSE[cols].columns,\n",
    "                 index=NYSE.index)\n",
    "\n",
    "# Create lagged data\n",
    "for lag in range(1, 6):\n",
    "    for col in cols:\n",
    "        newcol = np.zeros(X.shape[0]) * np.nan\n",
    "        newcol[lag:] = X[col].values[:-lag]\n",
    "        X.insert(len(X.columns), \"{0}_{1}\".format(col, lag), newcol)\n",
    "X.insert(len(X.columns), 'train', NYSE['train'])\n",
    "X = X.dropna()\n",
    "\n",
    "Y, train = X['log_volume'], X['train']\n",
    "X = X.drop(columns=['train'] + cols)\n",
    "X_day = pd.concat([X, pd.get_dummies(NYSE['day_of_week'])], axis=1).dropna()\n",
    "\n",
    "# Refit the data with lag 5 (NEED CHANGE)\n",
    "# ordered_cols = []\n",
    "# for lag in range(5,0,-1):\n",
    "#     for col in cols:\n",
    "#         ordered_cols.append('{0}_{1}'.format(col, lag))\n",
    "# X_day = X_day.reindex(columns=ordered_cols)\n",
    "# X_rnn = X_day.to_numpy().reshape((-1,5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70b7ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NYSEModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NYSEModel, self).__init__()\n",
    "        self.rnn = nn.RNN(3, 12, batch_first=True)\n",
    "        self.dense = nn.Linear(12, 1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    def forward(self, x):\n",
    "        val, h_n = self.rnn(x)\n",
    "        val = self.dense(self.dropout(val[:,-1]))\n",
    "        return torch.flatten(val)\n",
    "nyse_model = NYSEModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "404803cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\winso\\AppData\\Local\\Temp\\ipykernel_10572\\2602126799.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  Y_t = torch.tensor(Y[mask].astype(np.float32))\n",
      "C:\\Users\\winso\\AppData\\Local\\Temp\\ipykernel_10572\\2602126799.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  Y_t = torch.tensor(Y[mask].astype(np.float32))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "NYSEModel                                [1770, 5, 3]              [1770]                    --\n",
       "├─RNN: 1-1                               [1770, 5, 3]              [1770, 5, 12]             204\n",
       "├─Dropout: 1-2                           [1770, 12]                [1770, 12]                --\n",
       "├─Linear: 1-3                            [1770, 12]                [1770, 1]                 13\n",
       "===================================================================================================================\n",
       "Total params: 217\n",
       "Trainable params: 217\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 1.83\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 0.86\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.97\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = []\n",
    "for mask in [train, ~train]:\n",
    "    X_rnn_t = torch.tensor(X_rnn[mask].astype(np.float32))\n",
    "    Y_t = torch.tensor(Y[mask].astype(np.float32))\n",
    "    datasets.append(TensorDataset(X_rnn_t, Y_t))\n",
    "nyse_train, nyse_test = datasets\n",
    "\n",
    "summary(nyse_model, input_data=X_rnn_t, col_names=['input_size', 'output_size', 'num_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5fc2a79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64])\n",
      "torch.Size([64]) torch.Size([64])\n",
      "torch.Size([64]) torch.Size([64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type      | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | model | NYSEModel | 217    | train\n",
      "1 | loss  | MSELoss   | 0      | train\n",
      "--------------------------------------------\n",
      "217       Trainable params\n",
      "0         Non-trainable params\n",
      "217       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6203494668006897\n",
      "         test_r2            0.41125810146331787\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.6203494668006897, 'test_r2': 0.41125810146331787}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyse_dm = SimpleDataModule(nyse_train, nyse_test, num_workers=min(4, max_num_workers),\n",
    "                           validation=nyse_test, batch_size=64)\n",
    "for idx, (x, y) in enumerate(nyse_dm.train_dataloader()):\n",
    "    out = nyse_model(x)\n",
    "    print(y.size(), out.size())\n",
    "    if idx >= 2:\n",
    "        break\n",
    "    \n",
    "nyse_optimizer = RMSprop(nyse_model.parameters(), lr=0.001)\n",
    "nyse_module = SimpleModule.regression(nyse_model, optimizer=nyse_optimizer, metrics={'r2':R2Score()})\n",
    "nyse_trainer = Trainer(deterministic=True, max_epochs=200, enable_progress_bar=False, callbacks=[ErrorTracker()])\n",
    "nyse_trainer.fit(nyse_module, datamodule=nyse_dm)\n",
    "nyse_trainer.test(nyse_module, datamodule=nyse_dm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8a6c90",
   "metadata": {},
   "source": [
    "R-squared is shown to be around 41.284% for the lag-5 autoregressive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a491f1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DJ_return_1</th>\n",
       "      <th>log_volume_1</th>\n",
       "      <th>log_volatility_1</th>\n",
       "      <th>DJ_return_2</th>\n",
       "      <th>log_volume_2</th>\n",
       "      <th>log_volatility_2</th>\n",
       "      <th>DJ_return_3</th>\n",
       "      <th>log_volume_3</th>\n",
       "      <th>log_volatility_3</th>\n",
       "      <th>DJ_return_4</th>\n",
       "      <th>log_volume_4</th>\n",
       "      <th>log_volatility_4</th>\n",
       "      <th>DJ_return_5</th>\n",
       "      <th>log_volume_5</th>\n",
       "      <th>log_volatility_5</th>\n",
       "      <th>mon</th>\n",
       "      <th>tues</th>\n",
       "      <th>wed</th>\n",
       "      <th>thur</th>\n",
       "      <th>fri</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1962-12-10</th>\n",
       "      <td>0.046340</td>\n",
       "      <td>0.224779</td>\n",
       "      <td>-2.500970</td>\n",
       "      <td>-0.431397</td>\n",
       "      <td>0.935176</td>\n",
       "      <td>-2.366521</td>\n",
       "      <td>0.434813</td>\n",
       "      <td>2.283789</td>\n",
       "      <td>-2.418037</td>\n",
       "      <td>0.905200</td>\n",
       "      <td>1.517291</td>\n",
       "      <td>-2.529058</td>\n",
       "      <td>-0.549823</td>\n",
       "      <td>0.175075</td>\n",
       "      <td>-4.357078</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-12-11</th>\n",
       "      <td>-1.304126</td>\n",
       "      <td>0.605918</td>\n",
       "      <td>-1.366028</td>\n",
       "      <td>0.046340</td>\n",
       "      <td>0.224779</td>\n",
       "      <td>-2.500970</td>\n",
       "      <td>-0.431397</td>\n",
       "      <td>0.935176</td>\n",
       "      <td>-2.366521</td>\n",
       "      <td>0.434813</td>\n",
       "      <td>2.283789</td>\n",
       "      <td>-2.418037</td>\n",
       "      <td>0.905200</td>\n",
       "      <td>1.517291</td>\n",
       "      <td>-2.529058</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-12-12</th>\n",
       "      <td>-0.006294</td>\n",
       "      <td>-0.013661</td>\n",
       "      <td>-1.505667</td>\n",
       "      <td>-1.304126</td>\n",
       "      <td>0.605918</td>\n",
       "      <td>-1.366028</td>\n",
       "      <td>0.046340</td>\n",
       "      <td>0.224779</td>\n",
       "      <td>-2.500970</td>\n",
       "      <td>-0.431397</td>\n",
       "      <td>0.935176</td>\n",
       "      <td>-2.366521</td>\n",
       "      <td>0.434813</td>\n",
       "      <td>2.283789</td>\n",
       "      <td>-2.418037</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-12-13</th>\n",
       "      <td>0.377081</td>\n",
       "      <td>0.042552</td>\n",
       "      <td>-1.551515</td>\n",
       "      <td>-0.006294</td>\n",
       "      <td>-0.013661</td>\n",
       "      <td>-1.505667</td>\n",
       "      <td>-1.304126</td>\n",
       "      <td>0.605918</td>\n",
       "      <td>-1.366028</td>\n",
       "      <td>0.046340</td>\n",
       "      <td>0.224779</td>\n",
       "      <td>-2.500970</td>\n",
       "      <td>-0.431397</td>\n",
       "      <td>0.935176</td>\n",
       "      <td>-2.366521</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962-12-14</th>\n",
       "      <td>-0.411718</td>\n",
       "      <td>-0.419836</td>\n",
       "      <td>-1.597607</td>\n",
       "      <td>0.377081</td>\n",
       "      <td>0.042552</td>\n",
       "      <td>-1.551515</td>\n",
       "      <td>-0.006294</td>\n",
       "      <td>-0.013661</td>\n",
       "      <td>-1.505667</td>\n",
       "      <td>-1.304126</td>\n",
       "      <td>0.605918</td>\n",
       "      <td>-1.366028</td>\n",
       "      <td>0.046340</td>\n",
       "      <td>0.224779</td>\n",
       "      <td>-2.500970</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            DJ_return_1  log_volume_1  log_volatility_1  DJ_return_2  \\\n",
       "date                                                                   \n",
       "1962-12-10     0.046340      0.224779         -2.500970    -0.431397   \n",
       "1962-12-11    -1.304126      0.605918         -1.366028     0.046340   \n",
       "1962-12-12    -0.006294     -0.013661         -1.505667    -1.304126   \n",
       "1962-12-13     0.377081      0.042552         -1.551515    -0.006294   \n",
       "1962-12-14    -0.411718     -0.419836         -1.597607     0.377081   \n",
       "\n",
       "            log_volume_2  log_volatility_2  DJ_return_3  log_volume_3  \\\n",
       "date                                                                    \n",
       "1962-12-10      0.935176         -2.366521     0.434813      2.283789   \n",
       "1962-12-11      0.224779         -2.500970    -0.431397      0.935176   \n",
       "1962-12-12      0.605918         -1.366028     0.046340      0.224779   \n",
       "1962-12-13     -0.013661         -1.505667    -1.304126      0.605918   \n",
       "1962-12-14      0.042552         -1.551515    -0.006294     -0.013661   \n",
       "\n",
       "            log_volatility_3  DJ_return_4  log_volume_4  log_volatility_4  \\\n",
       "date                                                                        \n",
       "1962-12-10         -2.418037     0.905200      1.517291         -2.529058   \n",
       "1962-12-11         -2.366521     0.434813      2.283789         -2.418037   \n",
       "1962-12-12         -2.500970    -0.431397      0.935176         -2.366521   \n",
       "1962-12-13         -1.366028     0.046340      0.224779         -2.500970   \n",
       "1962-12-14         -1.505667    -1.304126      0.605918         -1.366028   \n",
       "\n",
       "            DJ_return_5  log_volume_5  log_volatility_5    mon   tues    wed  \\\n",
       "date                                                                           \n",
       "1962-12-10    -0.549823      0.175075         -4.357078   True  False  False   \n",
       "1962-12-11     0.905200      1.517291         -2.529058  False   True  False   \n",
       "1962-12-12     0.434813      2.283789         -2.418037  False  False   True   \n",
       "1962-12-13    -0.431397      0.935176         -2.366521  False  False  False   \n",
       "1962-12-14     0.046340      0.224779         -2.500970  False  False  False   \n",
       "\n",
       "             thur    fri  \n",
       "date                      \n",
       "1962-12-10  False  False  \n",
       "1962-12-11  False  False  \n",
       "1962-12-12  False  False  \n",
       "1962-12-13   True  False  \n",
       "1962-12-14  False   True  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4682a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
